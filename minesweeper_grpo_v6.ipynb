{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minesweeper LLM Competition - Custom GRPO Training\n",
    "\n",
    "## Goal\n",
    "Finetune an LLM with LoRA using GRPO to play Minesweeper by:\n",
    "- **Input**: JSON game state (board configuration)\n",
    "- **Output**: JSON action (reveal or flag a cell)\n",
    "\n",
    "Teams will compete to train the best Minesweeper-playing LLM!\n",
    "\n",
    "## Training Approach\n",
    "- **Model**: GPT-OSS 20B with LoRA or other models in the /root/.cache/huggingface/hub directory [**Any model other than /root/.cache/huggingface/hub will lead to disqualification**]\n",
    "- **Method**: GRPO (Group Relative Policy Optimization), SFT or any RL-policies (not just strict to use GRPO)\n",
    "- **Framework**: Unsloth (2-6x faster, 70% less VRAM)\n",
    "- **Hardware**: AMD GPU (ROCm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model with Unsloth\n",
    "\n",
    "Load GPT-OSS 20B with LoRA configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "#### Unsloth: `hf_xet==1.1.10` and `ipykernel>6.30.1` breaks progress bars. Disabling for now in XET.\n",
      "#### Unsloth: To re-enable progress bars, please downgrade to `ipykernel==6.30.1` or wait for a fix to\n",
      "https://github.com/huggingface/xet-core/issues/526\n",
      "INFO 02-15 06:41:34 [__init__.py:225] Automatically detected platform rocm.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "Unsloth: AMD currently is not stable with 4bit bitsandbytes. Disabling for now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 30] Read-only file system: '/root/.cache/huggingface/models--Unsloth--Llama-3.1-8B-Instruct/.no_exist'\n",
      "[2026-02-15 06:41:37] ERROR file_download.py:1559: Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 30] Read-only file system: '/root/.cache/huggingface/models--Unsloth--Llama-3.1-8B-Instruct/.no_exist'\n",
      "/usr/local/lib/python3.12/dist-packages/unsloth_zoo/gradient_checkpointing.py:348: UserWarning: expandable_segments not supported on this platform (Triggered internally at /app/pytorch/c10/hip/HIPAllocatorConfig.h:36.)\n",
      "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"{DEVICE_TYPE_TORCH}:{i}\") for i in range(n_gpus)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.10.6: Fast Llama patching. Transformers: 4.56.2. vLLM: 0.11.1rc2.dev161+g8a297115e.rocm700.\n",
      "   \\\\   /|    . Num GPUs = 1. Max memory: 255.688 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+gitb2fb688. ROCm Toolkit: 7.0.51831-a3e329ad8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 30] Read-only file system: '/root/.cache/huggingface/models--Unsloth--Llama-3.1-8B-Instruct/.no_exist'\n",
      "[2026-02-15 06:41:37] ERROR file_download.py:1559: Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 30] Read-only file system: '/root/.cache/huggingface/models--Unsloth--Llama-3.1-8B-Instruct/.no_exist'\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 30] Read-only file system: '/root/.cache/huggingface/models--Unsloth--Llama-3.1-8B-Instruct/.no_exist'\n",
      "[2026-02-15 06:41:37] ERROR file_download.py:1559: Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 30] Read-only file system: '/root/.cache/huggingface/models--Unsloth--Llama-3.1-8B-Instruct/.no_exist'\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 30] Read-only file system: '/root/.cache/huggingface/models--Unsloth--Llama-3.1-8B-Instruct/.no_exist'\n",
      "[2026-02-15 06:41:37] ERROR file_download.py:1559: Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 30] Read-only file system: '/root/.cache/huggingface/models--Unsloth--Llama-3.1-8B-Instruct/.no_exist'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257046b6f234476392c3509dde7c3da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 30] Read-only file system: '/root/.cache/huggingface/models--Unsloth--Llama-3.1-8B-Instruct/.no_exist'\n",
      "[2026-02-15 06:41:47] ERROR file_download.py:1559: Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 30] Read-only file system: '/root/.cache/huggingface/models--Unsloth--Llama-3.1-8B-Instruct/.no_exist'\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 30] Read-only file system: '/root/.cache/huggingface/models--Unsloth--Llama-3.1-8B-Instruct/.no_exist'\n",
      "[2026-02-15 06:41:47] ERROR file_download.py:1559: Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 30] Read-only file system: '/root/.cache/huggingface/models--Unsloth--Llama-3.1-8B-Instruct/.no_exist'\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 30] Read-only file system: '/root/.cache/huggingface/models--Unsloth--Llama-3.1-8B-Instruct/.no_exist'\n",
      "[2026-02-15 06:41:47] ERROR file_download.py:1559: Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 30] Read-only file system: '/root/.cache/huggingface/models--Unsloth--Llama-3.1-8B-Instruct/.no_exist'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Llama-3.1-8B-Instruct, rank=32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_HIP_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"HF_HUB_CACHE\"] = \"/root/.cache/huggingface\"\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 1024\n",
    "lora_rank = 32   # Higher rank for better learning capacity\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"Unsloth/Llama-3.1-8B-Instruct\",\n",
    "    load_in_4bit = True,\n",
    "    max_seq_length = max_seq_length,\n",
    "    torch_dtype = torch.bfloat16,\n",
    ")\n",
    "print(f\"Loaded Llama-3.1-8B-Instruct, rank={lora_rank}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add LoRA Adapters\n",
    "\n",
    "Add LoRA layers for efficient finetuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.10.6 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 83,886,080 || all params: 8,114,147,328 || trainable%: 1.0338\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank,\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha = lora_rank * 2,\n",
    "    lora_dropout = 0,\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    ")\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minesweeper Game Implementation\n",
    "\n",
    "Custom Minesweeper environment supporting:\n",
    "- Customizable board size and mine count\n",
    "- Actions: reveal or flag cells\n",
    "- Win: reveal all safe cells\n",
    "- Lose: reveal a mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Tuple, Optional, Set\n",
    "import random\n",
    "\n",
    "@dataclass\n",
    "class MinesweeperGame:\n",
    "    rows: int\n",
    "    cols: int\n",
    "    num_mines: int\n",
    "    seed: Optional[int] = None\n",
    "    _rng: random.Random = field(init=False, repr=False)\n",
    "    _board: List[List[int]] = field(init=False, repr=False)  # -1 = mine, 0-8 = count\n",
    "    _revealed: Set[Tuple[int, int]] = field(init=False, repr=False, default_factory=set)\n",
    "    _flagged: Set[Tuple[int, int]] = field(init=False, repr=False, default_factory=set)\n",
    "    _state: str = field(default=\"ongoing\", init=False, repr=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.num_mines >= self.rows * self.cols:\n",
    "            raise ValueError(\"Too many mines for board size\")\n",
    "        self._rng = random.Random(self.seed)\n",
    "        self._board = [[0 for _ in range(self.cols)] for _ in range(self.rows)]\n",
    "        self._place_mines()\n",
    "        self._calculate_numbers()\n",
    "\n",
    "    def _place_mines(self):\n",
    "        \"\"\"Place mines randomly on the board\"\"\"\n",
    "        positions = [(r, c) for r in range(self.rows) for c in range(self.cols)]\n",
    "        mine_positions = self._rng.sample(positions, self.num_mines)\n",
    "        for r, c in mine_positions:\n",
    "            self._board[r][c] = -1\n",
    "\n",
    "    def _calculate_numbers(self):\n",
    "        \"\"\"Calculate numbers for each cell based on adjacent mines\"\"\"\n",
    "        for r in range(self.rows):\n",
    "            for c in range(self.cols):\n",
    "                if self._board[r][c] == -1:\n",
    "                    continue\n",
    "                count = 0\n",
    "                for dr in [-1, 0, 1]:\n",
    "                    for dc in [-1, 0, 1]:\n",
    "                        if dr == 0 and dc == 0:\n",
    "                            continue\n",
    "                        nr, nc = r + dr, c + dc\n",
    "                        if 0 <= nr < self.rows and 0 <= nc < self.cols:\n",
    "                            if self._board[nr][nc] == -1:\n",
    "                                count += 1\n",
    "                self._board[r][c] = count\n",
    "\n",
    "    def _reveal_cell(self, row: int, col: int) -> bool:\n",
    "        \"\"\"Reveal a cell. Returns True if valid move, False if invalid.\n",
    "        Uses iterative flood-fill to avoid recursion limit on large boards.\n",
    "        (Issue #11: was recursive; Issue typo: fixed 'bself' -> 'self')\n",
    "        \"\"\"\n",
    "        if not (0 <= row < self.rows and 0 <= col < self.cols):\n",
    "            return False\n",
    "        if (row, col) in self._revealed or (row, col) in self._flagged:\n",
    "            return False\n",
    "\n",
    "        stack = [(row, col)]\n",
    "        while stack:\n",
    "            r, c = stack.pop()\n",
    "            if (r, c) in self._revealed:\n",
    "                continue\n",
    "\n",
    "            self._revealed.add((r, c))\n",
    "\n",
    "            # Hit a mine!\n",
    "            if self._board[r][c] == -1:\n",
    "                self._state = \"failed\"\n",
    "                return True\n",
    "\n",
    "            # Auto-reveal neighbors if cell is 0\n",
    "            if self._board[r][c] == 0:\n",
    "                for dr in [-1, 0, 1]:\n",
    "                    for dc in [-1, 0, 1]:\n",
    "                        if dr == 0 and dc == 0:\n",
    "                            continue\n",
    "                        nr, nc = r + dr, c + dc\n",
    "                        if (0 <= nr < self.rows and 0 <= nc < self.cols\n",
    "                                and (nr, nc) not in self._revealed\n",
    "                                and (nr, nc) not in self._flagged):\n",
    "                            stack.append((nr, nc))\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _flag_cell(self, row: int, col: int) -> bool:\n",
    "        \"\"\"Flag/unflag a cell. Returns True if valid, False if invalid\"\"\"\n",
    "        if not (0 <= row < self.rows and 0 <= col < self.cols):\n",
    "            return False\n",
    "        if (row, col) in self._revealed:\n",
    "            return False\n",
    "        \n",
    "        if (row, col) in self._flagged:\n",
    "            self._flagged.remove((row, col))\n",
    "        else:\n",
    "            self._flagged.add((row, col))\n",
    "        return True\n",
    "\n",
    "    def do_action(self, action: dict) -> str:\n",
    "        \"\"\"Execute an action and return a status string.\n",
    "\n",
    "        Returns one of:\n",
    "          'ok'               - valid move executed\n",
    "          'mine'             - revealed a mine (game over)\n",
    "          'win'              - game won after this move\n",
    "          'invalid_format'   - bad action dict / missing keys / bad types\n",
    "          'out_of_bounds'    - coordinates outside the board\n",
    "          'already_revealed' - cell was already revealed\n",
    "          'flagged_cell'     - tried to reveal a flagged cell\n",
    "          'invalid_flag'     - tried to flag a revealed cell\n",
    "          'game_over'        - game was already over before this call\n",
    "\n",
    "        (Issue #13: previously set state='failed' for ALL invalid moves,\n",
    "         conflating formatting errors with hitting a mine.)\n",
    "        \"\"\"\n",
    "        if self._state != \"ongoing\":\n",
    "            return \"game_over\"\n",
    "\n",
    "        if not isinstance(action, dict):\n",
    "            self._state = \"failed\"\n",
    "            return \"invalid_format\"\n",
    "\n",
    "        action_type = action.get(\"type\")\n",
    "        row = action.get(\"row\")\n",
    "        col = action.get(\"col\")\n",
    "\n",
    "        if action_type not in [\"reveal\", \"flag\"] or row is None or col is None:\n",
    "            self._state = \"failed\"\n",
    "            return \"invalid_format\"\n",
    "\n",
    "        try:\n",
    "            row, col = int(row), int(col)\n",
    "        except (ValueError, TypeError):\n",
    "            self._state = \"failed\"\n",
    "            return \"invalid_format\"\n",
    "\n",
    "        if not (0 <= row < self.rows and 0 <= col < self.cols):\n",
    "            self._state = \"failed\"\n",
    "            return \"out_of_bounds\"\n",
    "\n",
    "        if action_type == \"reveal\":\n",
    "            if (row, col) in self._revealed:\n",
    "                self._state = \"failed\"\n",
    "                return \"already_revealed\"\n",
    "            if (row, col) in self._flagged:\n",
    "                self._state = \"failed\"\n",
    "                return \"flagged_cell\"\n",
    "            valid = self._reveal_cell(row, col)\n",
    "        else:\n",
    "            if (row, col) in self._revealed:\n",
    "                self._state = \"failed\"\n",
    "                return \"invalid_flag\"\n",
    "            valid = self._flag_cell(row, col)\n",
    "\n",
    "        if not valid:\n",
    "            self._state = \"failed\"\n",
    "            return \"invalid_format\"\n",
    "\n",
    "        self._check_win()\n",
    "\n",
    "        if self._state == \"failed\":\n",
    "            return \"mine\"\n",
    "        if self._state == \"success\":\n",
    "            return \"win\"\n",
    "        return \"ok\"\n",
    "\n",
    "    def _check_win(self):\n",
    "        \"\"\"Check if player has won\"\"\"\n",
    "        total_cells = self.rows * self.cols\n",
    "        safe_cells = total_cells - self.num_mines\n",
    "        if len(self._revealed) == safe_cells:\n",
    "            self._state = \"success\"\n",
    "\n",
    "    def get_visible_board(self) -> List[List[str]]:\n",
    "        \"\"\"Get board state as player sees it\"\"\"\n",
    "        visible = []\n",
    "        for r in range(self.rows):\n",
    "            row = []\n",
    "            for c in range(self.cols):\n",
    "                if (r, c) in self._flagged:\n",
    "                    row.append('F')\n",
    "                elif (r, c) in self._revealed:\n",
    "                    val = self._board[r][c]\n",
    "                    row.append('*' if val == -1 else str(val))\n",
    "                else:\n",
    "                    row.append('.')\n",
    "            visible.append(row)\n",
    "        return visible\n",
    "\n",
    "    def state(self) -> str:\n",
    "        return self._state\n",
    "\n",
    "    def pretty_print(self) -> str:\n",
    "        \"\"\"Pretty print the board\"\"\"\n",
    "        visible = self.get_visible_board()\n",
    "        lines = []\n",
    "        \n",
    "        # Header\n",
    "        header = \"   \" + \" \".join(f\"{i:2d}\" for i in range(self.cols))\n",
    "        lines.append(header)\n",
    "        lines.append(\"  \" + \"â”€\" * (self.cols * 3 + 1))\n",
    "        \n",
    "        # Board\n",
    "        for r, row in enumerate(visible):\n",
    "            line = f\"{r:2d}â”‚ \" + \"  \".join(row)\n",
    "            lines.append(line)\n",
    "        \n",
    "        return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0  1  2  3  4  5\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      " 0â”‚ .  .  .  .  .  .\n",
      " 1â”‚ .  .  .  .  .  .\n",
      " 2â”‚ .  .  .  .  .  .\n",
      " 3â”‚ .  .  .  .  .  .\n",
      " 4â”‚ .  .  .  .  .  .\n",
      " 5â”‚ .  .  .  .  .  .\n",
      "State: ongoing\n",
      "\n",
      "After revealing (0,0):\n",
      "    0  1  2  3  4  5\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      " 0â”‚ 0  0  0  0  1  .\n",
      " 1â”‚ 0  0  1  1  2  .\n",
      " 2â”‚ 0  0  1  .  .  .\n",
      " 3â”‚ 0  0  1  .  .  .\n",
      " 4â”‚ 0  1  2  .  .  .\n",
      " 5â”‚ 0  1  .  .  .  .\n",
      "State: ongoing\n"
     ]
    }
   ],
   "source": [
    "# Create test game\n",
    "game = MinesweeperGame(rows=6, cols=6, num_mines=5)\n",
    "print(game.pretty_print())\n",
    "print(f\"State: {game.state()}\")\n",
    "\n",
    "# Test action\n",
    "game.do_action({\"type\": \"reveal\", \"row\": 0, \"col\": 0})\n",
    "print(\"\\nAfter revealing (0,0):\")\n",
    "print(game.pretty_print())\n",
    "print(f\"State: {game.state()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON Input/Output Format\n",
    "\n",
    "## Input Format (Game State)\n",
    "```json\n",
    "{\n",
    "  \"board\": [\n",
    "    [\"1\", \".\", \".\", \".\", \".\", \".\"],\n",
    "    [\".\", \".\", \".\", \".\", \".\", \".\"],\n",
    "    [\".\", \".\", \".\", \".\", \".\", \".\"],\n",
    "    [\".\", \".\", \".\", \".\", \".\", \".\"],\n",
    "    [\".\", \".\", \".\", \".\", \".\", \".\"],\n",
    "    [\".\", \".\", \".\", \".\", \".\", \".\"]\n",
    "  ],\n",
    "  \"rows\": 6,\n",
    "  \"cols\": 6,\n",
    "  \"mines\": 5,\n",
    "  \"flags_placed\": 0,\n",
    "  \"cells_revealed\": 0\n",
    "}\n",
    "```\n",
    "\n",
    "## Output Format (Action)\n",
    "```json\n",
    "{\"type\": \"reveal\", \"row\": 2, \"col\": 3}\n",
    "```\n",
    "or\n",
    "```json\n",
    "{\"type\": \"flag\", \"row\": 1, \"col\": 4}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 894 chars, 255 tokens\n",
      "Expert move: {'type': 'reveal', 'row': 0, 'col': 1}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "SYSTEM_PROMPT = \"You output JSON actions for Minesweeper. No text, only JSON.\"\n",
    "\n",
    "def format_state_for_llm(game: MinesweeperGame) -> str:\n",
    "    \"\"\"Compact prompt matching eval agent format.\"\"\"\n",
    "    state = {\n",
    "        \"board\": game.get_visible_board(),\n",
    "        \"rows\": game.rows,\n",
    "        \"cols\": game.cols,\n",
    "        \"mines\": game.num_mines,\n",
    "        \"flags_placed\": len(game._flagged),\n",
    "        \"cells_revealed\": len(game._revealed),\n",
    "    }\n",
    "    prompt = f\"\"\"You are playing Minesweeper. Analyze the game state and output your next move.\n",
    "\n",
    "You must output ONLY a valid JSON object. No explanation, no analysis, no text.\n",
    "\n",
    "Start your response immediately with {{ and end with }}.\n",
    "\n",
    "Do NOT output cell which is already revealed or flagged in the current state.\n",
    "\n",
    "Game state:\n",
    "{json.dumps(state)}\n",
    "\n",
    "Legend:\n",
    "- \".\" = unrevealed cell\n",
    "- \"F\" = flagged cell (suspected mine)\n",
    "- \"0\"-\"8\" = number of adjacent mines\n",
    "- \"*\" = revealed mine (game over)\n",
    "\n",
    "Output your next action as JSON:\n",
    "{{\"type\": \"reveal\", \"row\": <row_index>, \"col\": <col_index>}}\n",
    "or\n",
    "{{\"type\": \"flag\", \"row\": <row_index>, \"col\": <col_index>}}\n",
    "\n",
    "Your action:\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def parse_llm_action(response: str) -> dict:\n",
    "    \"\"\"Extract JSON action from LLM response. Returns LAST valid match.\"\"\"\n",
    "    import re\n",
    "    best = None\n",
    "    for match in re.finditer(r'\\{[^{}]*\\}', response):\n",
    "        try:\n",
    "            action = json.loads(match.group())\n",
    "            if (\"type\" in action and \"row\" in action and \"col\" in action\n",
    "                    and action[\"type\"] in [\"reveal\", \"flag\"]):\n",
    "                action[\"row\"] = int(action[\"row\"])\n",
    "                action[\"col\"] = int(action[\"col\"])\n",
    "                best = action\n",
    "        except (json.JSONDecodeError, ValueError, TypeError):\n",
    "            continue\n",
    "    return best\n",
    "\n",
    "\n",
    "def get_expert_move(game: MinesweeperGame) -> dict:\n",
    "    \"\"\"Oracle: generates REVEAL-focused expert moves.\n",
    "    Almost never flags â€” teaches model to reveal safely.\"\"\"\n",
    "    board = game.get_visible_board()\n",
    "    rows, cols = game.rows, game.cols\n",
    "\n",
    "    unrevealed = [(r, c) for r in range(rows) for c in range(cols) if board[r][c] == '.']\n",
    "    if not unrevealed: return None\n",
    "\n",
    "    # Find logically deducible cells\n",
    "    deducible_safe = []\n",
    "    deducible_mines = []\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            cell = board[r][c]\n",
    "            if not (cell.isdigit() and int(cell) > 0): continue\n",
    "            num = int(cell)\n",
    "            flagged, hidden = 0, []\n",
    "            for dr in [-1, 0, 1]:\n",
    "                for dc in [-1, 0, 1]:\n",
    "                    if dr == 0 and dc == 0: continue\n",
    "                    nr, nc = r + dr, c + dc\n",
    "                    if 0 <= nr < rows and 0 <= nc < cols:\n",
    "                        if board[nr][nc] == 'F': flagged += 1\n",
    "                        elif board[nr][nc] == '.': hidden.append((nr, nc))\n",
    "            if flagged == num:\n",
    "                for h in hidden:\n",
    "                    if h not in deducible_safe: deducible_safe.append(h)\n",
    "            remaining = num - flagged\n",
    "            if remaining > 0 and remaining == len(hidden):\n",
    "                for h in hidden:\n",
    "                    if h not in deducible_mines: deducible_mines.append(h)\n",
    "\n",
    "    # Priority 1: logically safe reveal (BEST move)\n",
    "    if deducible_safe:\n",
    "        r, c = random.choice(deducible_safe)\n",
    "        return {\"type\": \"reveal\", \"row\": r, \"col\": c}\n",
    "\n",
    "    # Priority 2: safe cell adjacent to numbered cells (strategic)\n",
    "    near = []\n",
    "    for (r, c) in unrevealed:\n",
    "        if game._board[r][c] == -1: continue  # skip mines\n",
    "        for dr in [-1,0,1]:\n",
    "            for dc in [-1,0,1]:\n",
    "                if dr == 0 and dc == 0: continue\n",
    "                nr, nc = r+dr, c+dc\n",
    "                if 0<=nr<rows and 0<=nc<cols and board[nr][nc].isdigit() and int(board[nr][nc])>0:\n",
    "                    near.append((r, c)); break\n",
    "            else: continue\n",
    "            break\n",
    "    if near:\n",
    "        r, c = random.choice(near)\n",
    "        return {\"type\": \"reveal\", \"row\": r, \"col\": c}\n",
    "\n",
    "    # Priority 3: safe corner/edge cell (good for opening)\n",
    "    safe = [(r, c) for (r, c) in unrevealed if game._board[r][c] != -1]\n",
    "    corners_edges = [(r, c) for (r, c) in safe\n",
    "                     if r in (0, rows-1) or c in (0, cols-1)]\n",
    "    if corners_edges:\n",
    "        r, c = random.choice(corners_edges)\n",
    "        return {\"type\": \"reveal\", \"row\": r, \"col\": c}\n",
    "\n",
    "    # Priority 4: any safe cell\n",
    "    if safe:\n",
    "        r, c = random.choice(safe)\n",
    "        return {\"type\": \"reveal\", \"row\": r, \"col\": c}\n",
    "\n",
    "    # Fallback (will hit mine â€” unavoidable sometimes)\n",
    "    r, c = random.choice(unrevealed)\n",
    "    return {\"type\": \"reveal\", \"row\": r, \"col\": c}\n",
    "\n",
    "\n",
    "game = MinesweeperGame(rows=6, cols=6, num_mines=5)\n",
    "prompt = format_state_for_llm(game)\n",
    "toks = tokenizer(prompt, return_tensors=\"pt\")\n",
    "print(f\"Prompt: {len(prompt)} chars, {toks['input_ids'].shape[1]} tokens\")\n",
    "print(f\"Expert move: {get_expert_move(game)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model Before Training\n",
    "\n",
    "See how the base model performs without finetuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFT dataset: 5000 demonstrations\n",
      "  Actions: {'reveal': 5000, 'flag': 0}\n",
      "  Reveal%: 100.0%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d865196870a941a094b04a8761d56099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=64):   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PHASE 1: SFT Training ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 5,000 | Num Epochs = 3 | Total steps = 1,875\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 2 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 83,886,080 of 8,114,147,328 (1.03% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1875/1875 15:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.488300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.106300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.097500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.095500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.096200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.094200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.091900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.091600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.088500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.091200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.088800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.087200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.086200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.084400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.082400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.082500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.083000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFT complete!\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "def generate_sft_dataset(num_samples=5000, rng_seed=42):\n",
    "    \"\"\"Generate REVEAL-focused expert demonstrations.\"\"\"\n",
    "    np.random.seed(rng_seed)\n",
    "    random.seed(rng_seed)\n",
    "    configs = [\n",
    "        (5,5,4),(5,5,5),(6,6,5),(6,6,7),(7,7,7),(7,7,10),\n",
    "        (8,8,10),(8,8,13),(9,9,12),(10,10,15),(6,10,10),(10,6,10),\n",
    "    ]\n",
    "    items = []\n",
    "    type_counts = {\"reveal\": 0, \"flag\": 0}\n",
    "    attempts = 0\n",
    "    while len(items) < num_samples and attempts < num_samples * 5:\n",
    "        attempts += 1\n",
    "        rows, cols, mines = random.choice(configs)\n",
    "        seed = np.random.randint(100000)\n",
    "        game = MinesweeperGame(rows=rows, cols=cols, num_mines=mines, seed=seed)\n",
    "        # Play 0-10 safe moves for varied mid-game states\n",
    "        for _ in range(np.random.randint(0, 11)):\n",
    "            if game.state() != \"ongoing\": break\n",
    "            board = game.get_visible_board()\n",
    "            safe = [(r,c) for r in range(rows) for c in range(cols)\n",
    "                    if board[r][c] == '.' and game._board[r][c] != -1]\n",
    "            if not safe: break\n",
    "            r, c = random.choice(safe)\n",
    "            game.do_action({\"type\": \"reveal\", \"row\": r, \"col\": c})\n",
    "        if game.state() != \"ongoing\": continue\n",
    "        expert = get_expert_move(game)\n",
    "        if expert is None: continue\n",
    "        type_counts[expert[\"type\"]] += 1\n",
    "        prompt = format_state_for_llm(game)\n",
    "        items.append(tokenizer.apply_chat_template([\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": json.dumps(expert)},\n",
    "        ], tokenize=False, add_generation_prompt=False))\n",
    "\n",
    "    print(f\"SFT dataset: {len(items)} demonstrations\")\n",
    "    print(f\"  Actions: {type_counts}\")\n",
    "    print(f\"  Reveal%: {type_counts['reveal']/len(items)*100:.1f}%\")\n",
    "    return Dataset.from_dict({\"text\": items[:num_samples]})\n",
    "\n",
    "sft_dataset = generate_sft_dataset(5000)\n",
    "\n",
    "# === SFT Training â€” 3 epochs ===\n",
    "FastLanguageModel.for_training(model)\n",
    "\n",
    "sft_trainer = SFTTrainer(\n",
    "    model=model, tokenizer=tokenizer, train_dataset=sft_dataset,\n",
    "    args=SFTConfig(\n",
    "        output_dir=\"minesweeper_sft\",\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=2,\n",
    "        num_train_epochs=3,\n",
    "        learning_rate=2e-4,\n",
    "        warmup_ratio=0.1,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        optim=\"adamw_8bit\",\n",
    "        logging_steps=100,\n",
    "        save_steps=9999,\n",
    "        max_seq_length=max_seq_length,\n",
    "        dataset_text_field=\"text\",\n",
    "        report_to=\"none\",\n",
    "    ),\n",
    ")\n",
    "print(\"=== PHASE 1: SFT Training ===\")\n",
    "sft_trainer.train()\n",
    "print(\"SFT complete!\")\n",
    "gc.collect(); torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRPO Reward Functions\n",
    "\n",
    "Define reward functions to guide the model's learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SFT MODEL TEST ===\n",
      "\n",
      "--- Seed 42 ---\n",
      "  Move 1: {'type': 'reveal', 'row': 5, 'col': 0} cell='.' -> ok\n",
      "  Move 2: {'type': 'reveal', 'row': 2, 'col': 3} cell='.' -> mine\n",
      "  Final: failed (2 moves)\n",
      "\n",
      "--- Seed 99 ---\n",
      "  Move 1: {'type': 'reveal', 'row': 5, 'col': 4} cell='.' -> ok\n",
      "  Move 2: {'type': 'reveal', 'row': 4, 'col': 1} cell='.' -> mine\n",
      "  Final: failed (2 moves)\n",
      "\n",
      "--- Seed 7 ---\n",
      "  Move 1: {'type': 'reveal', 'row': 0, 'col': 3} cell='.' -> mine\n",
      "  Final: failed (1 moves)\n",
      "\n",
      "--- Seed 123 ---\n",
      "  Move 1: {'type': 'reveal', 'row': 0, 'col': 5} cell='.' -> mine\n",
      "  Final: failed (1 moves)\n",
      "\n",
      "--- Seed 456 ---\n",
      "  Move 1: {'type': 'reveal', 'row': 0, 'col': 3} cell='.' -> ok\n",
      "  Move 2: {'type': 'reveal', 'row': 1, 'col': 3} cell='.' -> ok\n",
      "  Move 3: {'type': 'reveal', 'row': 1, 'col': 4} cell='.' -> ok\n",
      "  Move 4: {'type': 'reveal', 'row': 5, 'col': 3} cell='.' -> ok\n",
      "  Move 5: {'type': 'reveal', 'row': 4, 'col': 1} cell='.' -> ok\n",
      "  Move 6: FLAG-TOGGLE DETECTED on (5,3)\n",
      "  Final: ongoing (5 moves)\n",
      "\n",
      "Reward functions loaded (reveal-biased)\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "print(\"=== SFT MODEL TEST ===\\n\")\n",
    "for seed in [42, 99, 7, 123, 456]:\n",
    "    game = MinesweeperGame(rows=6, cols=6, num_mines=5, seed=seed)\n",
    "    print(f\"--- Seed {seed} ---\")\n",
    "    moves = 0\n",
    "    prev_actions = []\n",
    "    while game.state() == \"ongoing\" and moves < 20:\n",
    "        prompt = format_state_for_llm(game)\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            [{\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "             {\"role\": \"user\", \"content\": prompt}],\n",
    "            tokenize=False, add_generation_prompt=True)\n",
    "        output = model.generate(**tokenizer(text, return_tensors=\"pt\").to(model.device),\n",
    "            temperature=0.6, max_new_tokens=128, do_sample=True)\n",
    "        action = parse_llm_action(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "        if action is None: print(f\"  Move {moves+1}: PARSE FAIL\"); break\n",
    "        \n",
    "        # Detect flag-toggle loop\n",
    "        action_key = f\"{action['type']}_{action['row']}_{action['col']}\"\n",
    "        if len(prev_actions) >= 2 and action_key == prev_actions[-2]:\n",
    "            print(f\"  Move {moves+1}: FLAG-TOGGLE DETECTED on ({action['row']},{action['col']})\")\n",
    "            break\n",
    "        prev_actions.append(action_key)\n",
    "        \n",
    "        board = game.get_visible_board()\n",
    "        r, c = action[\"row\"], action[\"col\"]\n",
    "        cv = board[r][c] if 0<=r<game.rows and 0<=c<game.cols else \"OOB\"\n",
    "        result = game.do_action(action)\n",
    "        print(f\"  Move {moves+1}: {action} cell='{cv}' -> {result}\")\n",
    "        moves += 1\n",
    "    print(f\"  Final: {game.state()} ({moves} moves)\\n\")\n",
    "\n",
    "gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "# === Reward functions ===\n",
    "import numpy as np\n",
    "\n",
    "def is_logically_deducible_safe(game, row, col):\n",
    "    board = game.get_visible_board()\n",
    "    for dr in [-1, 0, 1]:\n",
    "        for dc in [-1, 0, 1]:\n",
    "            if dr == 0 and dc == 0: continue\n",
    "            nr, nc = row + dr, col + dc\n",
    "            if not (0 <= nr < game.rows and 0 <= nc < game.cols): continue\n",
    "            cell = board[nr][nc]\n",
    "            if not (cell.isdigit() and int(cell) > 0): continue\n",
    "            num = int(cell)\n",
    "            flagged, hidden = 0, []\n",
    "            for ddr in [-1, 0, 1]:\n",
    "                for ddc in [-1, 0, 1]:\n",
    "                    if ddr == 0 and ddc == 0: continue\n",
    "                    nnr, nnc = nr + ddr, nc + ddc\n",
    "                    if 0 <= nnr < game.rows and 0 <= nnc < game.cols:\n",
    "                        if board[nnr][nnc] == 'F': flagged += 1\n",
    "                        elif board[nnr][nnc] == '.': hidden.append((nnr, nnc))\n",
    "            if flagged == num and (row, col) in hidden: return True\n",
    "    return False\n",
    "\n",
    "def is_logically_deducible_mine(game, row, col):\n",
    "    board = game.get_visible_board()\n",
    "    for dr in [-1, 0, 1]:\n",
    "        for dc in [-1, 0, 1]:\n",
    "            if dr == 0 and dc == 0: continue\n",
    "            nr, nc = row + dr, col + dc\n",
    "            if not (0 <= nr < game.rows and 0 <= nc < game.cols): continue\n",
    "            cell = board[nr][nc]\n",
    "            if not (cell.isdigit() and int(cell) > 0): continue\n",
    "            num = int(cell)\n",
    "            flagged, hidden = 0, []\n",
    "            for ddr in [-1, 0, 1]:\n",
    "                for ddc in [-1, 0, 1]:\n",
    "                    if ddr == 0 and ddc == 0: continue\n",
    "                    nnr, nnc = nr + ddr, nc + ddc\n",
    "                    if 0 <= nnr < game.rows and 0 <= nnc < game.cols:\n",
    "                        if board[nnr][nnc] == 'F': flagged += 1\n",
    "                        elif board[nnr][nnc] == '.': hidden.append((nnr, nnc))\n",
    "            remaining = num - flagged\n",
    "            if remaining > 0 and remaining == len(hidden) and (row, col) in hidden: return True\n",
    "    return False\n",
    "\n",
    "def valid_json_reward(completions, **kwargs):\n",
    "    scores = []\n",
    "    for c in completions:\n",
    "        resp = c[0][\"content\"]\n",
    "        a = parse_llm_action(resp)\n",
    "        if a is None: scores.append(-5.0)\n",
    "        elif len(resp.strip()) < 60: scores.append(3.0)\n",
    "        elif len(resp.strip()) < 120: scores.append(2.0)\n",
    "        else: scores.append(0.5)\n",
    "    return scores\n",
    "\n",
    "def gameplay_scores(completions, **kwargs):\n",
    "    scores = []\n",
    "    seeds = kwargs.get(\"seed\", [])\n",
    "    mhs = kwargs.get(\"move_history\", [])\n",
    "    rl = kwargs.get(\"rows\", []); cl = kwargs.get(\"cols\", []); ml = kwargs.get(\"num_mines\", [])\n",
    "    for idx, comp in enumerate(completions):\n",
    "        resp = comp[0][\"content\"]\n",
    "        action = parse_llm_action(resp)\n",
    "        if action is None: scores.append(-10.0); continue\n",
    "        if idx >= len(seeds): scores.append(0.0); continue\n",
    "        r_ct=int(rl[idx]) if idx<len(rl) else 6\n",
    "        c_ct=int(cl[idx]) if idx<len(cl) else 6\n",
    "        m_ct=int(ml[idx]) if idx<len(ml) else 5\n",
    "        mh = json.loads(mhs[idx]) if isinstance(mhs[idx], str) else mhs[idx]\n",
    "        game = MinesweeperGame(rows=r_ct, cols=c_ct, num_mines=m_ct, seed=seeds[idx])\n",
    "        for prev in mh: game.do_action(prev)\n",
    "        board = game.get_visible_board()\n",
    "        try: row,col = int(action[\"row\"]),int(action[\"col\"])\n",
    "        except: scores.append(-10.0); continue\n",
    "        atype = action[\"type\"]\n",
    "        if not (0<=row<game.rows and 0<=col<game.cols): scores.append(-15.0); continue\n",
    "        cell = board[row][col]\n",
    "        if atype == \"reveal\":\n",
    "            if cell == 'F': scores.append(-8.0)\n",
    "            elif cell != '.': scores.append(-12.0)\n",
    "            elif game._board[row][col] == -1: scores.append(-25.0)\n",
    "            else:\n",
    "                base = 10.0\n",
    "                if is_logically_deducible_safe(game, row, col): base = 20.0\n",
    "                for dr in [-1,0,1]:\n",
    "                    for dc in [-1,0,1]:\n",
    "                        nr,nc = row+dr,col+dc\n",
    "                        if 0<=nr<game.rows and 0<=nc<game.cols and board[nr][nc].isdigit() and int(board[nr][nc])>0:\n",
    "                            base += 3.0; break\n",
    "                    else: continue\n",
    "                    break\n",
    "                sim = MinesweeperGame(rows=r_ct, cols=c_ct, num_mines=m_ct, seed=seeds[idx])\n",
    "                for prev in mh: sim.do_action(prev)\n",
    "                if sim.do_action({\"type\":\"reveal\",\"row\":row,\"col\":col}) == \"win\": base += 100.0\n",
    "                base += (row*c_ct+col)*0.01\n",
    "                scores.append(base)\n",
    "        elif atype == \"flag\":\n",
    "            if cell == 'F': scores.append(-15.0)  # HARSH: no toggling\n",
    "            elif cell != '.': scores.append(-8.0)\n",
    "            elif len(game._flagged) >= game.num_mines: scores.append(-10.0)\n",
    "            elif game._board[row][col] == -1:\n",
    "                base = 12.0  # Lower than reveal reward to prefer reveals\n",
    "                if is_logically_deducible_mine(game, row, col): base += 5.0\n",
    "                scores.append(base)\n",
    "            else: scores.append(-15.0)  # Wrong flag is HARSH\n",
    "        else: scores.append(-10.0)\n",
    "    return scores\n",
    "\n",
    "print(\"Reward functions loaded (reveal-biased)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Dataset\n",
    "\n",
    "Generate diverse game states for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRPO dataset: 2000 prompts\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def generate_grpo_dataset(num_samples=2000, rng_seed=99):\n",
    "    np.random.seed(rng_seed)\n",
    "    random.seed(rng_seed)\n",
    "    configs = [\n",
    "        (5,5,4),(5,5,5),(6,6,5),(6,6,7),(7,7,7),(7,7,10),\n",
    "        (8,8,10),(8,8,13),(9,9,12),(10,10,15),(6,10,10),(10,6,10),\n",
    "    ]\n",
    "    items = []\n",
    "    attempts = 0\n",
    "    while len(items) < num_samples and attempts < num_samples * 5:\n",
    "        attempts += 1\n",
    "        rows, cols, mines = random.choice(configs)\n",
    "        seed = np.random.randint(100000)\n",
    "        game = MinesweeperGame(rows=rows, cols=cols, num_mines=mines, seed=seed)\n",
    "        move_history = []\n",
    "        for _ in range(np.random.randint(0, 8)):\n",
    "            board = game.get_visible_board()\n",
    "            unrev = [(r,c) for r in range(rows) for c in range(cols) if board[r][c] == '.']\n",
    "            if not unrev or game.state() != \"ongoing\": break\n",
    "            r, c = random.choice(unrev)\n",
    "            a = {\"type\": \"flag\" if random.random() < 0.08 and len(game._flagged) < mines else \"reveal\", \"row\": r, \"col\": c}\n",
    "            game.do_action(a); move_history.append(a)\n",
    "        if game.state() == \"ongoing\":\n",
    "            items.append({\n",
    "                \"prompt\": [\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": format_state_for_llm(game)},\n",
    "                ],\n",
    "                \"seed\": seed, \"move_history\": json.dumps(move_history),\n",
    "                \"rows\": rows, \"cols\": cols, \"num_mines\": mines,\n",
    "            })\n",
    "    dataset = Dataset.from_list(items[:num_samples])\n",
    "    print(f\"GRPO dataset: {len(dataset)} prompts\")\n",
    "    return dataset\n",
    "\n",
    "dataset = generate_grpo_dataset(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure GRPO Training\n",
    "\n",
    "Set up GRPO trainer with all hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
      "We will change the batch size of 1 to the `num_generations` of 8\n",
      "GRPO: LR=5e-6, gens=8, steps=50, dr_grpo, grad_norm=0.1\n"
     ]
    }
   ],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    temperature = 1.0,\n",
    "    learning_rate = 5e-6,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.99,\n",
    "    weight_decay = 0.1,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"adamw_8bit\",\n",
    "    max_grad_norm = 0.1,\n",
    "    logging_steps = 1,\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 4,\n",
    "    num_generations = 8,\n",
    "    max_prompt_length = 800,\n",
    "    max_completion_length = 128,\n",
    "    max_steps = 50,\n",
    "    save_steps = 50,\n",
    "    report_to = \"none\",\n",
    "    output_dir = \"minesweeper_grpo_outputs\",\n",
    "    loss_type = \"dr_grpo\",\n",
    "    mask_truncated_completions = True,\n",
    ")\n",
    "print(f\"GRPO: LR=5e-6, gens=8, steps=50, dr_grpo, grad_norm=0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: 5 games every 25 steps (with loop detection)\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "class MinesweeperEvalCallback(TrainerCallback):\n",
    "    def __init__(self, eval_every=25, num_games=5):\n",
    "        self.eval_every = eval_every\n",
    "        self.num_games = num_games\n",
    "        self.best = 0.0\n",
    "    def on_step_end(self, args, state, control, model=None, processing_class=None, **kwargs):\n",
    "        if state.global_step % self.eval_every != 0: return\n",
    "        tok = processing_class\n",
    "        if tok is None or model is None: return\n",
    "        FastLanguageModel.for_inference(model)\n",
    "        torch.cuda.empty_cache()\n",
    "        wins, valid, invalid, total_mv = 0, 0, 0, 0\n",
    "        for i in range(self.num_games):\n",
    "            game = MinesweeperGame(rows=6, cols=6, num_mines=5, seed=10000+i)\n",
    "            mv = 0; prev_actions = []\n",
    "            while game.state() == \"ongoing\" and mv < 40:\n",
    "                p = format_state_for_llm(game)\n",
    "                t = tok.apply_chat_template(\n",
    "                    [{\"role\":\"system\",\"content\":SYSTEM_PROMPT},{\"role\":\"user\",\"content\":p}],\n",
    "                    tokenize=False, add_generation_prompt=True)\n",
    "                out = model.generate(**tok(t, return_tensors=\"pt\").to(model.device),\n",
    "                    temperature=0.6, max_new_tokens=128, do_sample=True)\n",
    "                a = parse_llm_action(tok.decode(out[0], skip_special_tokens=True))\n",
    "                if a is None: invalid += 1; break\n",
    "                ak = f\"{a['type']}_{a['row']}_{a['col']}\"\n",
    "                if len(prev_actions) >= 2 and ak == prev_actions[-2]: break\n",
    "                prev_actions.append(ak)\n",
    "                valid += 1; game.do_action(a); mv += 1\n",
    "                if i == 0 and state.global_step <= self.eval_every:\n",
    "                    print(f\"    Move {mv}: {a} -> {game.state()}\")\n",
    "            total_mv += mv\n",
    "            if game.state() == \"success\": wins += 1\n",
    "        wr = wins / self.num_games\n",
    "        best = \" ** BEST **\" if wr > self.best else \"\"\n",
    "        if wr > self.best: self.best = wr\n",
    "        print(f\"\\n[Eval@{state.global_step}] Wins:{wins}/{self.num_games} ({wr*100:.0f}%) \"\n",
    "              f\"Valid:{valid/(max(valid+invalid,1))*100:.0f}% AvgMoves:{total_mv/self.num_games:.1f}{best}\\n\")\n",
    "        FastLanguageModel.for_training(model)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "eval_callback = MinesweeperEvalCallback(eval_every=25, num_games=5)\n",
    "print(\"Eval: 5 games every 25 steps (with loop detection)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n",
    "Start GRPO training with reward functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PHASE 2: GRPO (50 steps) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 2,000 | Num Epochs = 1 | Total steps = 50\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 4 x 1) = 32\n",
      " \"-____-\"     Trainable parameters = 83,886,080 of 8,114,147,328 (1.03% trained)\n",
      "`generation_config` default values have been modified to match model-specific defaults: {'max_length': 131072, 'temperature': 0.6, 'top_p': 0.9}. If this is not desired, please set these values explicitly.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 02:45, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>reward</th>\n",
       "      <th>reward_std</th>\n",
       "      <th>completions / mean_length</th>\n",
       "      <th>completions / min_length</th>\n",
       "      <th>completions / max_length</th>\n",
       "      <th>completions / clipped_ratio</th>\n",
       "      <th>completions / mean_terminated_length</th>\n",
       "      <th>completions / min_terminated_length</th>\n",
       "      <th>completions / max_terminated_length</th>\n",
       "      <th>sampling / sampling_logp_difference / mean</th>\n",
       "      <th>sampling / sampling_logp_difference / max</th>\n",
       "      <th>sampling / importance_sampling_ratio / min</th>\n",
       "      <th>sampling / importance_sampling_ratio / mean</th>\n",
       "      <th>sampling / importance_sampling_ratio / max</th>\n",
       "      <th>kl</th>\n",
       "      <th>rewards / valid_json_reward / mean</th>\n",
       "      <th>rewards / valid_json_reward / std</th>\n",
       "      <th>rewards / gameplay_scores / mean</th>\n",
       "      <th>rewards / gameplay_scores / std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>12.666875</td>\n",
       "      <td>10.273813</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135193</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.666875</td>\n",
       "      <td>11.755674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.414375</td>\n",
       "      <td>16.902935</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.093985</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.585625</td>\n",
       "      <td>17.464191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.891562</td>\n",
       "      <td>15.707942</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.111759</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.108438</td>\n",
       "      <td>17.848860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.112188</td>\n",
       "      <td>15.276940</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.081155</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.887812</td>\n",
       "      <td>17.770535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>-1.835000</td>\n",
       "      <td>16.034588</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.146345</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.835000</td>\n",
       "      <td>17.892859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>4.128750</td>\n",
       "      <td>15.937254</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.107548</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.128750</td>\n",
       "      <td>15.639008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.935938</td>\n",
       "      <td>12.362643</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.083625</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.064062</td>\n",
       "      <td>16.142885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.376250</td>\n",
       "      <td>17.221165</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.084268</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.623750</td>\n",
       "      <td>17.525503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.613438</td>\n",
       "      <td>17.747551</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.107485</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.386563</td>\n",
       "      <td>19.055725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>8.023125</td>\n",
       "      <td>12.056473</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.133132</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.023125</td>\n",
       "      <td>13.828140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.428750</td>\n",
       "      <td>16.553486</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.046432</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.571250</td>\n",
       "      <td>16.385572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.260000</td>\n",
       "      <td>18.278378</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.112959</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.740000</td>\n",
       "      <td>18.337793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>4.655000</td>\n",
       "      <td>11.908745</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.136422</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.655000</td>\n",
       "      <td>16.210321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>4.542188</td>\n",
       "      <td>13.853497</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.089311</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.542188</td>\n",
       "      <td>16.152527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.675625</td>\n",
       "      <td>9.375864</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.084929</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.675625</td>\n",
       "      <td>12.935410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>5.698750</td>\n",
       "      <td>16.114330</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.143250</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.698750</td>\n",
       "      <td>15.805799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.689687</td>\n",
       "      <td>17.433317</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.070076</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.689687</td>\n",
       "      <td>18.478931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.759375</td>\n",
       "      <td>17.376055</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.240625</td>\n",
       "      <td>17.515224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.157187</td>\n",
       "      <td>13.896622</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.088371</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.842812</td>\n",
       "      <td>16.687836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>8.424686</td>\n",
       "      <td>14.105969</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.107066</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.424687</td>\n",
       "      <td>13.749134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>8.165937</td>\n",
       "      <td>10.547029</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.166069</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.165937</td>\n",
       "      <td>13.891689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.991875</td>\n",
       "      <td>11.293349</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.085262</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.008125</td>\n",
       "      <td>17.473118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.790313</td>\n",
       "      <td>17.463625</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.058881</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.790313</td>\n",
       "      <td>17.404020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>5.212812</td>\n",
       "      <td>16.440449</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.130402</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.212813</td>\n",
       "      <td>16.694393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>5.663438</td>\n",
       "      <td>15.472308</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.096534</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.663437</td>\n",
       "      <td>15.153775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.678750</td>\n",
       "      <td>14.369819</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.089953</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.321250</td>\n",
       "      <td>16.794847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.234063</td>\n",
       "      <td>16.763283</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.051982</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.765937</td>\n",
       "      <td>17.451149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.385625</td>\n",
       "      <td>13.704643</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.077656</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385625</td>\n",
       "      <td>15.859663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>4.426250</td>\n",
       "      <td>11.957613</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.168688</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.426250</td>\n",
       "      <td>14.766875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>10.267813</td>\n",
       "      <td>7.110180</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.267812</td>\n",
       "      <td>10.243808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>3.189062</td>\n",
       "      <td>14.120178</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.117148</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189063</td>\n",
       "      <td>17.297848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>7.137187</td>\n",
       "      <td>12.718056</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.085818</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.137187</td>\n",
       "      <td>14.887321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.421875</td>\n",
       "      <td>7.213040</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.087888</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.421875</td>\n",
       "      <td>12.843826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>7.402812</td>\n",
       "      <td>11.526896</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.129582</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.402812</td>\n",
       "      <td>15.835647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>3.109062</td>\n",
       "      <td>15.982300</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.112028</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109062</td>\n",
       "      <td>17.033833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.874688</td>\n",
       "      <td>18.045582</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.050183</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.874688</td>\n",
       "      <td>17.540756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>-0.100625</td>\n",
       "      <td>14.418423</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.133597</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.100625</td>\n",
       "      <td>16.580488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>-0.833125</td>\n",
       "      <td>17.775692</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.101758</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.833125</td>\n",
       "      <td>18.309507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>8.350000</td>\n",
       "      <td>10.971144</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.176595</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.350000</td>\n",
       "      <td>12.825447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>7.529687</td>\n",
       "      <td>11.962633</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.529687</td>\n",
       "      <td>14.227654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>10.357500</td>\n",
       "      <td>9.340245</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.149227</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.357500</td>\n",
       "      <td>11.100121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.738438</td>\n",
       "      <td>17.471443</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.073760</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.738438</td>\n",
       "      <td>17.565937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>7.894688</td>\n",
       "      <td>12.379038</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.118635</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.894687</td>\n",
       "      <td>15.031968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>3.818125</td>\n",
       "      <td>16.941828</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.130235</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.818125</td>\n",
       "      <td>16.986582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>10.864062</td>\n",
       "      <td>7.368038</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.120667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.864062</td>\n",
       "      <td>10.477326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.863438</td>\n",
       "      <td>16.025866</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.082222</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.863438</td>\n",
       "      <td>18.079288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.857812</td>\n",
       "      <td>15.570209</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.059929</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.857812</td>\n",
       "      <td>15.575703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.928437</td>\n",
       "      <td>9.389435</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.063268</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.928437</td>\n",
       "      <td>16.172001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.834687</td>\n",
       "      <td>16.166420</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.036540</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165313</td>\n",
       "      <td>15.658390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.605000</td>\n",
       "      <td>15.365087</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>0.057054</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.605000</td>\n",
       "      <td>14.877526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Move 1: {'type': 'reveal', 'row': 2, 'col': 0} -> ongoing\n",
      "    Move 2: {'type': 'reveal', 'row': 3, 'col': 1} -> failed\n",
      "\n",
      "[Eval@25] Wins:0/5 (0%) Valid:100% AvgMoves:2.0\n",
      "\n",
      "\n",
      "[Eval@50] Wins:1/5 (20%) Valid:100% AvgMoves:3.8 ** BEST **\n",
      "\n",
      "GRPO complete!\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "FastLanguageModel.for_training(model)\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model=model, processing_class=tokenizer,\n",
    "    reward_funcs=[valid_json_reward, gameplay_scores],\n",
    "    args=training_args, train_dataset=dataset,\n",
    "    callbacks=[eval_callback],\n",
    ")\n",
    "print(\"=== PHASE 2: GRPO (50 steps) ===\")\n",
    "trainer.train()\n",
    "print(\"GRPO complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Trained Model\n",
    "\n",
    "Evaluate the finetuned model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL MODEL TEST ===\n",
      "\n",
      "--- Seed 42 ---\n",
      "  Move 1: {'type': 'reveal', 'row': 0, 'col': 3} cell='.' -> ok\n",
      "  Move 2: {'type': 'reveal', 'row': 1, 'col': 1} cell='.' -> mine\n",
      "  Final: failed (2 moves)\n",
      "\n",
      "--- Seed 99 ---\n",
      "  Move 1: {'type': 'reveal', 'row': 4, 'col': 5} cell='.' -> ok\n",
      "  Move 2: {'type': 'reveal', 'row': 4, 'col': 1} cell='.' -> mine\n",
      "  Final: failed (2 moves)\n",
      "\n",
      "--- Seed 7 ---\n",
      "  Move 1: {'type': 'reveal', 'row': 5, 'col': 3} cell='.' -> ok\n",
      "  Move 2: {'type': 'reveal', 'row': 3, 'col': 1} cell='.' -> ok\n",
      "  Move 3: {'type': 'reveal', 'row': 0, 'col': 3} cell='.' -> mine\n",
      "  Final: failed (3 moves)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "print(\"=== FINAL MODEL TEST ===\\n\")\n",
    "for seed in [42, 99, 7]:\n",
    "    game = MinesweeperGame(rows=6, cols=6, num_mines=5, seed=seed)\n",
    "    print(f\"--- Seed {seed} ---\")\n",
    "    moves = 0\n",
    "    while game.state() == \"ongoing\" and moves < 15:\n",
    "        prompt = format_state_for_llm(game)\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            [{\"role\":\"system\",\"content\":SYSTEM_PROMPT},{\"role\":\"user\",\"content\":prompt}],\n",
    "            tokenize=False, add_generation_prompt=True)\n",
    "        output = model.generate(**tokenizer(text, return_tensors=\"pt\").to(model.device),\n",
    "            temperature=0.6, max_new_tokens=128, do_sample=True)\n",
    "        action = parse_llm_action(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "        if action is None: print(f\"  Move {moves+1}: PARSE FAIL\"); break\n",
    "        board = game.get_visible_board()\n",
    "        r, c = action[\"row\"], action[\"col\"]\n",
    "        cv = board[r][c] if 0<=r<game.rows and 0<=c<game.cols else \"OOB\"\n",
    "        result = game.do_action(action)\n",
    "        print(f\"  Move {moves+1}: {action} cell='{cv}' -> {result}\")\n",
    "        moves += 1\n",
    "    print(f\"  Final: {game.state()} ({moves} moves)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Play Complete Games\n",
    "\n",
    "Test the model on multiple complete games:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [6x6/5m] Game 1: LOSS (4 moves)\n",
      "  [6x6/5m] Game 2: LOSS (1 moves)\n",
      "  [6x6/5m] Game 3: LOSS (4 moves)\n",
      "  [6x6/5m] Game 20: WIN (5 moves)\n",
      "  6x6/5m: 1/20 (5%), avg 3.0 moves\n",
      "\n",
      "  [8x8/10m] Game 1: LOSS (2 moves)\n",
      "  [8x8/10m] Game 2: LOSS (4 moves)\n",
      "  [8x8/10m] Game 3: LOSS (9 moves)\n",
      "  8x8/10m: 0/20 (0%), avg 3.3 moves\n",
      "\n",
      "  [10x10/15m] Game 1: LOSS (4 moves)\n",
      "  [10x10/15m] Game 2: LOSS (2 moves)\n",
      "  [10x10/15m] Game 3: LOSS (2 moves)\n",
      "  10x10/15m: 0/20 (0%), avg 4.0 moves\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def play_full_game(model, tokenizer, rows=6, cols=6, num_mines=5, seed=None, max_moves=80):\n",
    "    game = MinesweeperGame(rows=rows, cols=cols, num_mines=num_mines, seed=seed)\n",
    "    moves = 0\n",
    "    prev_actions = []\n",
    "    while game.state() == \"ongoing\" and moves < max_moves:\n",
    "        prompt = format_state_for_llm(game)\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            [{\"role\":\"system\",\"content\":SYSTEM_PROMPT},{\"role\":\"user\",\"content\":prompt}],\n",
    "            tokenize=False, add_generation_prompt=True)\n",
    "        output = model.generate(**tokenizer(text, return_tensors=\"pt\").to(model.device),\n",
    "            temperature=0.6, max_new_tokens=128, do_sample=True)\n",
    "        action = parse_llm_action(tokenizer.decode(output[0], skip_special_tokens=True))\n",
    "        if action is None: break\n",
    "        # Detect loops\n",
    "        ak = f\"{action['type']}_{action['row']}_{action['col']}\"\n",
    "        if len(prev_actions) >= 2 and ak == prev_actions[-2]: break\n",
    "        prev_actions.append(ak)\n",
    "        game.do_action(action); moves += 1\n",
    "    return game, moves\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "for name, r, c, m in [(\"6x6/5m\",6,6,5),(\"8x8/10m\",8,8,10),(\"10x10/15m\",10,10,15)]:\n",
    "    wins, total_mv = 0, 0\n",
    "    for i in range(20):\n",
    "        g, mv = play_full_game(model, tokenizer, r, c, m, seed=i)\n",
    "        total_mv += mv\n",
    "        if g.state() == \"success\": wins += 1\n",
    "        if i < 3 or g.state() == \"success\":\n",
    "            print(f\"  [{name}] Game {i+1}: {'WIN' if g.state()=='success' else 'LOSS'} ({mv} moves)\")\n",
    "    print(f\"  {name}: {wins}/20 ({wins*5}%), avg {total_mv/20:.1f} moves\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model\n",
    "\n",
    "Save your trained model for competition submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignored error while writing commit hash to /root/.cache/huggingface/models--Unsloth--Llama-3.1-8B-Instruct/refs/main: [Errno 30] Read-only file system: '/root/.cache/huggingface/models--Unsloth--Llama-3.1-8B-Instruct/refs/main'.\n",
      "[2026-02-15 06:30:08] WARNING _snapshot_download.py:300: Ignored error while writing commit hash to /root/.cache/huggingface/models--Unsloth--Llama-3.1-8B-Instruct/refs/main: [Errno 30] Read-only file system: '/root/.cache/huggingface/models--Unsloth--Llama-3.1-8B-Instruct/refs/main'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Found cache directory /root/.cache/huggingface, but lack R/W/X permissions. Cannot use cache.\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'copied_tokenizer_model_from_cache' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnboundLocalError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m tokenizer.save_pretrained(\u001b[33m\"\u001b[39m\u001b[33mmy_minesweeper_model\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoRA saved.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_pretrained_merged\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmy_minesweeper_model_merged\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_method\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmerged_16bit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMerged model saved to: my_minesweeper_model_merged/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mUpdate agents/minesweeper_model.py:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/unsloth/save.py:2499\u001b[39m, in \u001b[36munsloth_generic_save_pretrained_merged\u001b[39m\u001b[34m(self, save_directory, tokenizer, save_method, push_to_hub, token, is_main_process, state_dict, save_function, max_shard_size, safe_serialization, variant, save_peft_format, tags, temporary_location, maximum_memory_usage)\u001b[39m\n\u001b[32m   2497\u001b[39m arguments[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m\n\u001b[32m   2498\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m arguments[\u001b[33m\"\u001b[39m\u001b[33mself\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m2499\u001b[39m \u001b[43munsloth_generic_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43marguments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2500\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m):\n\u001b[32m   2501\u001b[39m     gc.collect()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/unsloth/save.py:2445\u001b[39m, in \u001b[36munsloth_generic_save\u001b[39m\u001b[34m(model, tokenizer, save_directory, save_method, push_to_hub, token, is_main_process, state_dict, save_function, max_shard_size, safe_serialization, variant, save_peft_format, use_temp_dir, commit_message, private, create_pr, revision, commit_description, tags, temporary_location, maximum_memory_usage)\u001b[39m\n\u001b[32m   2442\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m save_method == \u001b[33m\"\u001b[39m\u001b[33mmerged_4bit_forced\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2443\u001b[39m     save_method = \u001b[33m\"\u001b[39m\u001b[33mmerged_4bit\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2445\u001b[39m \u001b[43mmerge_and_overwrite_lora\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2446\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2447\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m                \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2448\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m            \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2449\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_directory\u001b[49m\u001b[43m       \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2450\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m          \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2451\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprivate\u001b[49m\u001b[43m              \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2452\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m                \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2453\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_method\u001b[49m\u001b[43m          \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2454\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dtype\u001b[49m\u001b[43m         \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2455\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlow_disk_space_usage\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2456\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_temp_file\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2457\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2458\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/unsloth_zoo/saving_utils.py:1224\u001b[39m, in \u001b[36mmerge_and_overwrite_lora\u001b[39m\u001b[34m(get_model_name, model, tokenizer, save_directory, push_to_hub, private, token, save_method, output_dtype, low_disk_space_usage, use_temp_file, cleanup_temp_file)\u001b[39m\n\u001b[32m   1216\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownloading safetensors for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1217\u001b[39m     snapshot_download(\n\u001b[32m   1218\u001b[39m         repo_id = model_name,\n\u001b[32m   1219\u001b[39m         local_dir = save_directory,\n\u001b[32m   1220\u001b[39m         allow_patterns = safe_tensor_index_files + safetensors_list,\n\u001b[32m   1221\u001b[39m         local_dir_use_symlinks = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1222\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1224\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcopied_tokenizer_model_from_cache\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m low_disk_space_usage \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_path:\n\u001b[32m   1225\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempting to download tokenizer.model for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1226\u001b[39m     snapshot_download(\n\u001b[32m   1227\u001b[39m         repo_id = model_name,\n\u001b[32m   1228\u001b[39m         local_dir = save_directory,\n\u001b[32m   1229\u001b[39m         allow_patterns = [\u001b[33m\"\u001b[39m\u001b[33mtokenizer.model\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   1230\u001b[39m         local_dir_use_symlinks = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1231\u001b[39m     )\n",
      "\u001b[31mUnboundLocalError\u001b[39m: cannot access local variable 'copied_tokenizer_model_from_cache' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"my_minesweeper_model\")\n",
    "tokenizer.save_pretrained(\"my_minesweeper_model\")\n",
    "print(\"LoRA saved.\")\n",
    "\n",
    "model.save_pretrained_merged(\n",
    "    \"my_minesweeper_model_merged\",\n",
    "    tokenizer,\n",
    "    save_method = \"merged_16bit\",\n",
    ")\n",
    "print(\"Merged model saved to: my_minesweeper_model_merged/\")\n",
    "print(\"\\nUpdate agents/minesweeper_model.py:\")\n",
    "print('  model_name = \"/workspace/my_minesweeper_model_merged\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competition Tips\n",
    "\n",
    "## Improve Your Model:\n",
    "\n",
    "1. **Adjust Reward Functions**\n",
    "   - Increase rewards for logical deduction\n",
    "   - Add penalties for random moves\n",
    "   - Reward flagging correct mines\n",
    "\n",
    "2. **Tune Hyperparameters**\n",
    "   - Increase `max_steps` for longer training\n",
    "   - Adjust `learning_rate` (try 1e-5 to 1e-4)\n",
    "   - Increase `lora_rank` for more capacity\n",
    "   - Adjust `num_generations` (2-8)\n",
    "\n",
    "3. **Better Training Data**\n",
    "   - Generate more diverse states\n",
    "   - Include harder scenarios (more mines)\n",
    "   - Add states requiring logical deduction\n",
    "\n",
    "4. **Advanced Techniques**\n",
    "   - Multi-step rollouts in reward function\n",
    "   - Curriculum learning (easy â†’ hard boards)\n",
    "   - Ensemble multiple models\n",
    "\n",
    "## Team Strategy:\n",
    "- Experiment with different reward functions\n",
    "- Try different board sizes during training\n",
    "- Analyze failed games to improve rewards\n",
    "- Use temperature sampling during evaluation\n",
    "\n",
    "Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
